{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Simple",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wIRlKwVK63YZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Modules"
      ]
    },
    {
      "metadata": {
        "id": "odLhsO4T60Ul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "from torchtext.data import Field\n",
        "from torchtext.data import TabularDataset\n",
        "from torchtext.data import BucketIterator, Iterator\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GD06MBbSYbZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a2a853a9-464d-413c-8622-a791de4c4af9"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "dt-TiL_N62Xm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SEED = 479\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# !CUDA_LAUNCH_BLOCKING=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mKuHV-hFYIaj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h2gSM4M_YiuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QzpQ6dme6ut6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing Data"
      ]
    },
    {
      "metadata": {
        "id": "S_1PkOHwka8K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "XKuMjidtkcru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "92b1f67b-5e15-430c-d2a7-59e7e28549cf"
      },
      "cell_type": "code",
      "source": [
        "# read in data\n",
        "path = '4_19_lyrics_with_tags.csv'\n",
        "ly = pd.read_csv(path, delimiter = \",\", dtype = {'lyrics':str})\n",
        "ly.head(3)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>title</th>\n",
              "      <th>language</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>track_id</th>\n",
              "      <th>tags</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lena Philipsson</td>\n",
              "      <td>006</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I had come in the name of love\\nWith a mission...</td>\n",
              "      <td>TRMMMKI128F931D80D</td>\n",
              "      <td>pop</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Shawn Colvin</td>\n",
              "      <td>The Heart Of Saturday</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Well you gassed her up\\nBehind the wheel\\nWith...</td>\n",
              "      <td>TRQFODA128F93319C3</td>\n",
              "      <td>pop</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dying Fetus</td>\n",
              "      <td>Ethos of Coercion</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Castigation of the offenders, no punishment ou...</td>\n",
              "      <td>TRLXQQL128F4291A8F</td>\n",
              "      <td>rock</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            artist                   title  language  \\\n",
              "0  Lena Philipsson                     006       1.0   \n",
              "1     Shawn Colvin   The Heart Of Saturday       1.0   \n",
              "2      Dying Fetus       Ethos of Coercion       1.0   \n",
              "\n",
              "                                              lyrics            track_id  \\\n",
              "0  I had come in the name of love\\nWith a mission...  TRMMMKI128F931D80D   \n",
              "1  Well you gassed her up\\nBehind the wheel\\nWith...  TRQFODA128F93319C3   \n",
              "2  Castigation of the offenders, no punishment ou...  TRLXQQL128F4291A8F   \n",
              "\n",
              "   tags  category  \n",
              "0   pop         2  \n",
              "1   pop         2  \n",
              "2  rock         1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "xPa8shiPnFK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# declare field\n",
        "tokenize = lambda x: x.split()\n",
        "\n",
        "# TEXT = data.Field(tokenize = 'spacy')\n",
        "TEXT = Field(sequential=True, tokenize=tokenize, lower=True,\n",
        "             stop_words = STOPWORDS)\n",
        "LABEL = Field(sequential=False, use_vocab=True, is_target=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vDE1w0zeo5Kl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# setup dataset\n",
        "\n",
        "trn_vld_tst_fields = [(\"artist\", None), (\"title\", None), (\"language\", None),\n",
        "                      (\"lyrics\", TEXT), (\"track_id\", None), (\"tags\", LABEL)]\n",
        "\n",
        "trn_vld_tst_dataset = TabularDataset(\n",
        "    path=\"4_19_lyrics_with_tags.csv\", format='csv',\n",
        "    skip_header=True, fields=trn_vld_tst_fields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O54HlwOFrjQi",
        "colab_type": "code",
        "outputId": "ab811878-756d-463c-e3e7-0ce1d67bd5c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# split dataset into trn, tst, vld\n",
        "# with ratio: 6, 3, 1\n",
        "# use random.seed\n",
        "\n",
        "trn, vld, tst = trn_vld_tst_dataset.split(\n",
        "    split_ratio = [0.6, 0.3, 0.1],\n",
        "    random_state = random.seed(SEED))\n",
        "\n",
        "print('Number of training examples:', len(trn), sep = ' ')\n",
        "print('Number of validation examples:', len(vld), sep = ' ')\n",
        "print('Number of testing examples:', len(tst), sep = ' ')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 46731\n",
            "Number of validation examples: 7788\n",
            "Number of testing examples: 23366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hjgRRsFRqMqu",
        "colab_type": "code",
        "outputId": "9f4fe2cd-9e28-4e4f-edf3-2510e6f8eaac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# setup dictionary on train dataset\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(trn, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(trn)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E_VVry2c015Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create iterators\n",
        "BATCH_SIZE = 64\n",
        "trn_iter, vld_iter = BucketIterator.splits(\n",
        "    (trn, vld), device = device,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.lyrics))\n",
        "\n",
        "tst_iter = Iterator(tst, batch_size=BATCH_SIZE, \n",
        "                     device=device, \n",
        "                     sort=False, \n",
        "                     sort_within_batch=False, \n",
        "                     repeat=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-DOAMjco4Zf7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the Model"
      ]
    },
    {
      "metadata": {
        "id": "jOPhIykq4bFX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "  \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bx5dd1Zn7nVR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* input_dim = the dimension of the one-hot vectors = vocabulary size\n",
        "\n",
        "* embedding_dim = size of the dense word vectors = 50~250, depending on input_dim\n",
        "\n",
        "* hidden_dim = size of the hidden states = 100~500, depending on input_dim, embedding_dim, complexity of the task\n",
        "\n",
        "* output_dim = number of classes"
      ]
    },
    {
      "metadata": {
        "id": "F_0dVIGr7hPZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 120\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 7\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Afb-gsbe88Uh",
        "colab_type": "code",
        "outputId": "2a5fca3d-6667-42ae-cc35-858303320477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def count_trnable_para(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_trnable_para(model):,} trainable parameters')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,098,807 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MdNqRs8y9Pt8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bNymv25S9R9i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ]
    },
    {
      "metadata": {
        "id": "sW3XmB9v9TSV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6m8SEMLt_7mv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def multiclass_accuracy(model_output, y):\n",
        "    model_preds = torch.sigmoid(model_output).max(1)[1]\n",
        "    correct = (model_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sZBBEUNyC472",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define train function\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # model.train(): put the model in \"training mode\"\n",
        "    # which turns on dropout and batch normalization.\n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # zero the gradients\n",
        "        # PyTorch does not automatically remove (zero) the gradients\n",
        "        # of the last gradient calculation\n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        predictions = model(batch.lyrics).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.tags)\n",
        "        \n",
        "        acc = multiclass_accuracy(predictions, batch.tags)\n",
        "        \n",
        "        # update model's parameters\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ivPZBPlSEsiX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define evaluate function\n",
        "# similar to train, but don't want update parameters\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # model.eval(): puts the model in \"evaluation mode\"\n",
        "    # which turns off dropout and batch normalization\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.lyrics).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.tags)\n",
        "            \n",
        "            acc = multiclass_accuracy(predictions, batch.tags)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "prVt5ydiFSxB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tell us how long an epoch takes\n",
        "# to compare training times between models.\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aHwpmqInFlPX",
        "colab_type": "code",
        "outputId": "90a12194-cb25-4a0b-dfd4-2542fd59c9f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 50\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    trn_loss, trn_acc = train(model, trn_iter, optimizer, criterion)\n",
        "    vld_loss, vld_acc = evaluate(model, vld_iter, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if vld_loss < best_valid_loss:\n",
        "        best_valid_loss = vld_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {trn_loss:.3f} | Train Acc: {trn_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {vld_loss:.3f} |  Val. Acc: {vld_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.936 | Train Acc: 74.31%\n",
            "\t Val. Loss: 0.972 |  Val. Acc: 73.74%\n",
            "Epoch: 02 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.929 | Train Acc: 74.41%\n",
            "\t Val. Loss: 0.995 |  Val. Acc: 73.14%\n",
            "Epoch: 03 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.928 | Train Acc: 74.44%\n",
            "\t Val. Loss: 0.944 |  Val. Acc: 74.30%\n",
            "Epoch: 04 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.929 | Train Acc: 74.44%\n",
            "\t Val. Loss: 0.989 |  Val. Acc: 73.11%\n",
            "Epoch: 05 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.942 | Train Acc: 74.07%\n",
            "\t Val. Loss: 1.471 |  Val. Acc: 49.86%\n",
            "Epoch: 06 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.943 | Train Acc: 73.94%\n",
            "\t Val. Loss: 1.397 |  Val. Acc: 52.36%\n",
            "Epoch: 07 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.938 | Train Acc: 74.19%\n",
            "\t Val. Loss: 1.236 |  Val. Acc: 67.11%\n",
            "Epoch: 08 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.935 | Train Acc: 74.39%\n",
            "\t Val. Loss: 1.121 |  Val. Acc: 72.73%\n",
            "Epoch: 09 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.932 | Train Acc: 74.40%\n",
            "\t Val. Loss: 1.035 |  Val. Acc: 73.53%\n",
            "Epoch: 10 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.931 | Train Acc: 74.45%\n",
            "\t Val. Loss: 0.995 |  Val. Acc: 74.20%\n",
            "Epoch: 11 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.929 | Train Acc: 74.45%\n",
            "\t Val. Loss: 0.993 |  Val. Acc: 73.37%\n",
            "Epoch: 12 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.930 | Train Acc: 74.45%\n",
            "\t Val. Loss: 1.013 |  Val. Acc: 73.76%\n",
            "Epoch: 13 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.930 | Train Acc: 74.45%\n",
            "\t Val. Loss: 1.048 |  Val. Acc: 71.86%\n",
            "Epoch: 14 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.929 | Train Acc: 74.48%\n",
            "\t Val. Loss: 0.989 |  Val. Acc: 73.44%\n",
            "Epoch: 15 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.927 | Train Acc: 74.46%\n",
            "\t Val. Loss: 0.977 |  Val. Acc: 73.55%\n",
            "Epoch: 16 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.926 | Train Acc: 74.50%\n",
            "\t Val. Loss: 1.008 |  Val. Acc: 72.82%\n",
            "Epoch: 17 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.926 | Train Acc: 74.52%\n",
            "\t Val. Loss: 1.031 |  Val. Acc: 71.30%\n",
            "Epoch: 18 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.932 | Train Acc: 74.43%\n",
            "\t Val. Loss: 1.039 |  Val. Acc: 71.82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HXWHEdykMXne",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "tst_loss, tst_acc = evaluate(model, tst_iter, criterion)\n",
        "\n",
        "print(f'Test Loss: {tst_loss:.3f} | Test Acc: {tst_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cGW0Gy_MW9oi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}