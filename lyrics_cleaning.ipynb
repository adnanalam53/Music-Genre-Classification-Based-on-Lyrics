{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lyrics_cleaning.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hcBL4XF8FrV7","colab_type":"text"},"source":["# Lyrics Cleaning  \n","Wengie Wang"]},{"cell_type":"code","metadata":{"id":"B2DqDuISWqGV","colab_type":"code","outputId":"8e0aea3c-6d7e-43d6-aed9-04b797abed81","executionInfo":{"status":"ok","timestamp":1555714296683,"user_tz":300,"elapsed":1557,"user":{"displayName":"CHRISTINA GREGIS","photoUrl":"","userId":"08586587474345405670"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["import logging\n","import pandas as pd\n","import numpy as np\n","from numpy import random\n","import gensim\n","\n","import nltk\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import classification_report\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n","\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","from nltk.corpus import stopwords\n","import re\n","from bs4 import BeautifulSoup\n","\n","import nltk\n","nltk.download('stopwords')\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"],"name":"stderr"},{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"5S8qTCXAZCbi","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import csv\n","import torch\n","from torchtext import data\n","import os\n","import numpy as np\n","import math\n","import scipy as scp\n","import re"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5YLluR0CY96s","colab_type":"code","colab":{}},"source":["RANDOM_SEED = 123\n","DEVICE = \"cuda\"\n","ly = pd.read_csv(\"4_19_lyrics_with_tags.csv\", dtype = {'lyrics':str})\n","ly[8:30]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K34ogk8dWy-z","colab_type":"code","colab":{}},"source":["REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;|\\n]')\n","BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n","STOPWORDS = set(stopwords.words('english'))\n","lyrics = ly[\"lyrics\"]\n","def clean_text(text):\n","    \"\"\"\n","        text: a string\n","        \n","        return: modified initial string\n","    \"\"\"\n","    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n","    text = text.lower() # lowercase text\n","    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n","    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n","    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n","    return text\n","    \n","lyrics = lyrics.apply(clean_text)\n","ly[\"lyrics\"]=lyrics\n","\n","print(ly[8:30])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l6HZog4nCeT9","colab_type":"text"},"source":[""]}]}